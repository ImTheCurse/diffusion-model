{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce87df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.42.0.dev0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.19.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.18.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.8/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.3.0+cu121)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.8/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting diffusers[torch]\n",
      "  Downloading diffusers-0.34.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (7.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (3.14.0)\n",
      "Collecting huggingface-hub>=0.27.0 (from diffusers[torch])\n",
      "  Downloading huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (0.4.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (10.3.0)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.8/dist-packages (from diffusers[torch]) (2.3.0+cu121)\n",
      "Collecting accelerate>=0.31.0 (from diffusers[torch])\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.31.0->diffusers[torch]) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.31.0->diffusers[torch]) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate>=0.31.0->diffusers[torch]) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.27.0->diffusers[torch]) (2024.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.27.0->diffusers[torch]) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.27.0->diffusers[torch]) (4.11.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.27.0->diffusers[torch])\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->diffusers[torch]) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->diffusers[torch]) (12.4.127)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib_metadata->diffusers[torch]) (3.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->diffusers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.4->diffusers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.4->diffusers[torch]) (1.3.0)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Downloading huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.34.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m184.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m202.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: hf-xet, huggingface-hub, diffusers, accelerate\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.0\n",
      "    Uninstalling huggingface-hub-0.23.0:\n",
      "      Successfully uninstalled huggingface-hub-0.23.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.30.1\n",
      "    Uninstalling accelerate-0.30.1:\n",
      "      Successfully uninstalled accelerate-0.30.1\n",
      "Successfully installed accelerate-1.0.1 diffusers-0.34.0 hf-xet-1.1.5 huggingface-hub-0.34.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torchvision\n",
    "!pip install \"diffusers[torch]\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947493e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import CLIPTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc364324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering artist_id=22:  81%|████████▏ | 81444/100000 [15:06<03:26, 89.80it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Load the full WikiArt dataset from HugGAN\n",
    "dataset = load_dataset(\"huggan/wikiart\", split=\"train\",streaming=True)\n",
    "\n",
    "# Filter by artist ID with tqdm\n",
    "artist_id = 22\n",
    "filtered = []\n",
    "\n",
    "# Limit tqdm bar to something large but finite (streaming doesn't give length)\n",
    "for sample in tqdm(dataset, desc=f\"Filtering artist_id={artist_id}\", total=100_000):\n",
    "    if sample[\"artist\"] == artist_id:\n",
    "        filtered.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa79fa-665a-43e7-8937-2f42e0907b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- get subject images ---\n",
    "sub_dir = \"subject_images\"\n",
    "os.makedirs(sub_dir, exist_ok=True)\n",
    "\n",
    "for idx, sample in enumerate(filtered):\n",
    "    image = sample[\"image\"]  # already a PIL Image\n",
    "    assert isinstance(image, Image.Image), f\"Item {idx} is not a PIL image\"\n",
    "\n",
    "    # Optional: encode metadata into filename if desired\n",
    "    artist = sample.get(\"artist\", \"unknown\")\n",
    "    genre = sample.get(\"genre\", \"unknown\")\n",
    "    style = sample.get(\"style\", \"unknown\")\n",
    "\n",
    "    filename = f\"img_{idx:05d}_artist{artist}_genre{genre}_style{style}.jpg\"\n",
    "    filepath = os.path.join(sub_dir, filename)\n",
    "\n",
    "    image.save(filepath)\n",
    "\n",
    "print(f\"✅ Saved {len(filtered)} images to '{sub_dir}/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad3915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c54e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:04<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# ----- Load pretrained Stable Diffusion -----\n",
    "model_id = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(device)\n",
    "tokenizer: CLIPTokenizer = pipe.tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5a732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Add a new token -----\n",
    "new_token = \"[skaz]\"\n",
    "class_token = \"artwork\"\n",
    "num_added = tokenizer.add_tokens([new_token])\n",
    "pipe.text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "new_token_id = tokenizer.convert_tokens_to_ids(new_token)\n",
    "\n",
    "# we use class token in order to avoid drift, as mentioned in the dreambooth paper.\n",
    "class_token_id = tokenizer.convert_tokens_to_ids(class_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41b70c97-3238-484b-944f-e28cef241386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7984284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- fine-tune new token embedding -----\n",
    "embedding_layer = pipe.text_encoder.get_input_embeddings()\n",
    "\n",
    "# Freeze all text encoder params\n",
    "for param in pipe.text_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the embedding weights\n",
    "embedding_layer.weight.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    embedding_layer.weight\n",
    "], lr=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b88ca215",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fafc3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDreamBoothDataset(Dataset):\n",
    "    def __init__(self, subject_dir, prior_dir, transform):\n",
    "        # build full paths, and only keep files\n",
    "        self.subject_images = [\n",
    "            os.path.join(subject_dir, f)\n",
    "            for f in os.listdir(subject_dir)\n",
    "            if os.path.isfile(os.path.join(subject_dir, f))\n",
    "        ]\n",
    "        self.prior_images = [\n",
    "            os.path.join(prior_dir, f)\n",
    "            for f in os.listdir(prior_dir)\n",
    "            if os.path.isfile(os.path.join(prior_dir, f))\n",
    "        ]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # so we cycle through the smaller set repeatedly\n",
    "        return max(len(self.subject_images), len(self.prior_images))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # wrap around\n",
    "        subj_path  = self.subject_images[idx % len(self.subject_images)]\n",
    "        prior_path = self.prior_images[idx % len(self.prior_images)]\n",
    "\n",
    "        # open & ensure RGB\n",
    "        img_subj  = Image.open(subj_path).convert(\"RGB\")\n",
    "        img_prior = Image.open(prior_path).convert(\"RGB\")\n",
    "\n",
    "        return self.transform(img_subj), self.transform(img_prior)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a73b3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prompt = \"A painting in the style of Van Gogh\"\n",
    "num_images = 400\n",
    "pri_dir = \"prior_images\"\n",
    "os.makedirs(pri_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38e127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 59.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_images):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"generating prior image #{i}\")\n",
    "    image = pipe(class_prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "    image.save(os.path.join(pri_dir, f\"class_image_{i:03}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "143df46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDreamBoothDataset(\"subject_images\", \"prior_images\",transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70b14afd-8b99-4cd4-8497-82d035a9270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0000] Loss: 0.7971 | Subj: 0.3815 | Prior: 0.4156\n",
      "[0010] Loss: 0.0782 | Subj: 0.0374 | Prior: 0.0408\n",
      "[0020] Loss: 0.3964 | Subj: 0.1696 | Prior: 0.2267\n",
      "[0030] Loss: 1.0207 | Subj: 0.4731 | Prior: 0.5476\n",
      "[0040] Loss: 0.8250 | Subj: 0.3836 | Prior: 0.4414\n",
      "[0050] Loss: 0.8168 | Subj: 0.4479 | Prior: 0.3689\n",
      "[0060] Loss: 0.3136 | Subj: 0.1276 | Prior: 0.1860\n",
      "[0070] Loss: 0.0263 | Subj: 0.0103 | Prior: 0.0161\n",
      "[0080] Loss: 0.0100 | Subj: 0.0041 | Prior: 0.0059\n",
      "[0090] Loss: 1.0049 | Subj: 0.5022 | Prior: 0.5027\n",
      "[0100] Loss: 0.0644 | Subj: 0.0260 | Prior: 0.0384\n",
      "[0110] Loss: 0.8375 | Subj: 0.4725 | Prior: 0.3650\n",
      "[0120] Loss: 0.0106 | Subj: 0.0104 | Prior: 0.0003\n",
      "[0130] Loss: 0.2777 | Subj: 0.1185 | Prior: 0.1592\n",
      "[0140] Loss: 0.8461 | Subj: 0.4029 | Prior: 0.4433\n",
      "[0150] Loss: 0.1992 | Subj: 0.0805 | Prior: 0.1187\n",
      "[0160] Loss: 1.0240 | Subj: 0.5834 | Prior: 0.4406\n",
      "[0170] Loss: 0.3257 | Subj: 0.1894 | Prior: 0.1364\n",
      "[0180] Loss: 0.7059 | Subj: 0.3700 | Prior: 0.3360\n",
      "[0190] Loss: 0.2950 | Subj: 0.1378 | Prior: 0.1572\n",
      "[0200] Loss: 0.2645 | Subj: 0.1350 | Prior: 0.1295\n",
      "[0210] Loss: 1.0854 | Subj: 0.5439 | Prior: 0.5415\n",
      "[0220] Loss: 0.0353 | Subj: 0.0151 | Prior: 0.0202\n",
      "[0230] Loss: 0.0877 | Subj: 0.0407 | Prior: 0.0470\n",
      "[0240] Loss: 0.0904 | Subj: 0.0383 | Prior: 0.0521\n",
      "[0250] Loss: 0.0684 | Subj: 0.0282 | Prior: 0.0401\n",
      "[0260] Loss: 1.0184 | Subj: 0.5581 | Prior: 0.4603\n",
      "[0270] Loss: 0.2626 | Subj: 0.1029 | Prior: 0.1596\n",
      "[0280] Loss: 0.2197 | Subj: 0.0764 | Prior: 0.1433\n",
      "[0290] Loss: 0.0088 | Subj: 0.0028 | Prior: 0.0059\n",
      "[0300] Loss: 0.0099 | Subj: 0.0044 | Prior: 0.0055\n",
      "[0310] Loss: 0.7504 | Subj: 0.4555 | Prior: 0.2950\n",
      "[0320] Loss: 0.2957 | Subj: 0.1571 | Prior: 0.1386\n",
      "[0330] Loss: 0.5545 | Subj: 0.2441 | Prior: 0.3104\n",
      "[0340] Loss: 0.4302 | Subj: 0.2214 | Prior: 0.2088\n",
      "[0350] Loss: 0.0125 | Subj: 0.0055 | Prior: 0.0070\n",
      "[0360] Loss: 0.0272 | Subj: 0.0101 | Prior: 0.0171\n",
      "[0370] Loss: 0.0609 | Subj: 0.0235 | Prior: 0.0375\n",
      "[0380] Loss: 0.0077 | Subj: 0.0023 | Prior: 0.0054\n",
      "[0390] Loss: 0.1225 | Subj: 0.0486 | Prior: 0.0739\n",
      "[0400] Loss: 0.4976 | Subj: 0.2433 | Prior: 0.2543\n",
      "[0410] Loss: 0.2065 | Subj: 0.0950 | Prior: 0.1115\n",
      "[0420] Loss: 0.0826 | Subj: 0.0351 | Prior: 0.0475\n",
      "[0430] Loss: 0.0564 | Subj: 0.0211 | Prior: 0.0352\n",
      "[0440] Loss: 0.1376 | Subj: 0.0577 | Prior: 0.0799\n",
      "[0450] Loss: 0.2350 | Subj: 0.1012 | Prior: 0.1339\n",
      "[0460] Loss: 0.1053 | Subj: 0.0459 | Prior: 0.0594\n",
      "[0470] Loss: 0.6626 | Subj: 0.3178 | Prior: 0.3448\n",
      "[0480] Loss: 0.0099 | Subj: 0.0047 | Prior: 0.0053\n",
      "[0490] Loss: 0.0691 | Subj: 0.0282 | Prior: 0.0409\n",
      "[0500] Loss: 0.8446 | Subj: 0.4287 | Prior: 0.4158\n",
      "[0510] Loss: 0.0557 | Subj: 0.0240 | Prior: 0.0316\n",
      "[0520] Loss: 0.0543 | Subj: 0.0227 | Prior: 0.0316\n",
      "[0530] Loss: 1.3692 | Subj: 0.6681 | Prior: 0.7011\n",
      "[0540] Loss: 0.6838 | Subj: 0.3626 | Prior: 0.3212\n",
      "[0550] Loss: 0.8190 | Subj: 0.4448 | Prior: 0.3742\n",
      "[0560] Loss: 0.1756 | Subj: 0.0854 | Prior: 0.0902\n",
      "[0570] Loss: 0.8206 | Subj: 0.4164 | Prior: 0.4042\n",
      "[0580] Loss: 0.2055 | Subj: 0.0997 | Prior: 0.1058\n",
      "[0590] Loss: 0.3269 | Subj: 0.1578 | Prior: 0.1691\n",
      "[0600] Loss: 0.6638 | Subj: 0.3370 | Prior: 0.3269\n",
      "[0610] Loss: 0.0106 | Subj: 0.0046 | Prior: 0.0060\n",
      "[0620] Loss: 0.0134 | Subj: 0.0069 | Prior: 0.0066\n",
      "[0630] Loss: 0.1130 | Subj: 0.0513 | Prior: 0.0617\n",
      "[0640] Loss: 0.2087 | Subj: 0.0762 | Prior: 0.1325\n",
      "[0650] Loss: 0.1453 | Subj: 0.0530 | Prior: 0.0924\n",
      "[0660] Loss: 0.6140 | Subj: 0.3052 | Prior: 0.3088\n",
      "[0670] Loss: 0.0376 | Subj: 0.0138 | Prior: 0.0238\n",
      "[0680] Loss: 0.0082 | Subj: 0.0027 | Prior: 0.0055\n",
      "[0690] Loss: 0.1919 | Subj: 0.0922 | Prior: 0.0997\n",
      "[0700] Loss: 1.9636 | Subj: 0.9830 | Prior: 0.9806\n",
      "[0710] Loss: 0.0513 | Subj: 0.0221 | Prior: 0.0292\n",
      "[0720] Loss: 0.4416 | Subj: 0.2336 | Prior: 0.2080\n",
      "[0730] Loss: 0.2851 | Subj: 0.1462 | Prior: 0.1389\n",
      "[0740] Loss: 0.0099 | Subj: 0.0035 | Prior: 0.0065\n",
      "[0750] Loss: 0.3903 | Subj: 0.1862 | Prior: 0.2041\n",
      "[0760] Loss: 0.0259 | Subj: 0.0122 | Prior: 0.0136\n",
      "[0770] Loss: 0.0088 | Subj: 0.0032 | Prior: 0.0055\n",
      "[0780] Loss: 0.2447 | Subj: 0.1048 | Prior: 0.1399\n",
      "[0790] Loss: 0.0554 | Subj: 0.0191 | Prior: 0.0363\n",
      "[0800] Loss: 0.2543 | Subj: 0.1282 | Prior: 0.1261\n",
      "[0810] Loss: 0.0230 | Subj: 0.0091 | Prior: 0.0139\n",
      "[0820] Loss: 0.1211 | Subj: 0.0499 | Prior: 0.0712\n",
      "[0830] Loss: 0.3369 | Subj: 0.1695 | Prior: 0.1674\n",
      "[0840] Loss: 0.8785 | Subj: 0.4640 | Prior: 0.4145\n",
      "[0850] Loss: 0.0451 | Subj: 0.0181 | Prior: 0.0269\n",
      "[0860] Loss: 0.1527 | Subj: 0.0781 | Prior: 0.0746\n",
      "[0870] Loss: 0.0163 | Subj: 0.0067 | Prior: 0.0096\n",
      "[0880] Loss: 0.7439 | Subj: 0.3581 | Prior: 0.3858\n",
      "[0890] Loss: 0.1469 | Subj: 0.0595 | Prior: 0.0874\n",
      "[0900] Loss: 0.0428 | Subj: 0.0164 | Prior: 0.0264\n",
      "[0910] Loss: 1.2333 | Subj: 0.6145 | Prior: 0.6189\n",
      "[0920] Loss: 0.7181 | Subj: 0.3478 | Prior: 0.3703\n",
      "[0930] Loss: 0.1015 | Subj: 0.0447 | Prior: 0.0568\n",
      "[0940] Loss: 0.1152 | Subj: 0.0424 | Prior: 0.0728\n",
      "[0950] Loss: 0.3654 | Subj: 0.1871 | Prior: 0.1783\n",
      "[0960] Loss: 0.2018 | Subj: 0.0822 | Prior: 0.1195\n",
      "[0970] Loss: 0.8047 | Subj: 0.3492 | Prior: 0.4555\n",
      "[0980] Loss: 0.4188 | Subj: 0.2010 | Prior: 0.2179\n",
      "[0990] Loss: 0.3905 | Subj: 0.1671 | Prior: 0.2234\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----- Training loop -----\n",
    "num_epochs = 1000\n",
    "lmbda = 1.0  # prior preservation weight\n",
    "\n",
    "for step, (x_subj, x_prior) in enumerate(dataloader):\n",
    "    if step >= num_epochs:\n",
    "        break\n",
    "\n",
    "    # Move to device\n",
    "    x_subj = x_subj.to(device)\n",
    "    x_prior = x_prior.to(device)\n",
    "\n",
    "    # --- Tokenize prompts ---\n",
    "    subj_prompt  = f\"a photo of {new_token} {class_token}\"\n",
    "    prior_prompt = f\"a photo of {class_token}\"\n",
    "    subj_ids  = tokenizer(subj_prompt,  return_tensors=\"pt\").input_ids.to(device)\n",
    "    prior_ids = tokenizer(prior_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    # --- Text embeddings (frozen) ---\n",
    "    with torch.no_grad():\n",
    "        subj_embeds  = pipe.text_encoder(subj_ids)[0]\n",
    "        prior_embeds = pipe.text_encoder(prior_ids)[0]\n",
    "\n",
    "    # --- Encode RGB images → 4-channel latents (float16) ---\n",
    "    with torch.no_grad():\n",
    "        x_subj_fp16  = x_subj.to(torch.float16)\n",
    "        x_prior_fp16 = x_prior.to(torch.float16)\n",
    "\n",
    "        latents_subj  = pipe.vae.encode(x_subj_fp16).latent_dist.sample()\n",
    "        latents_prior = pipe.vae.encode(x_prior_fp16).latent_dist.sample()\n",
    "\n",
    "        latents_subj  *= pipe.vae.config.scaling_factor\n",
    "        latents_prior *= pipe.vae.config.scaling_factor\n",
    "\n",
    "    # --- Noise injection ---\n",
    "    noise = torch.randn_like(latents_subj)\n",
    "    batch_size = latents_subj.shape[0]\n",
    "    t = torch.randint(\n",
    "        0,\n",
    "        pipe.scheduler.config.num_train_timesteps,\n",
    "        (batch_size,),\n",
    "        device=device,\n",
    "    ).long()\n",
    "\n",
    "    alphas = pipe.scheduler.alphas_cumprod.to(device)\n",
    "    alpha_t = alphas[t].view(-1, 1, 1, 1).sqrt()\n",
    "    sigma_t = (1 - alphas[t]).view(-1, 1, 1, 1).sqrt()\n",
    "\n",
    "    noisy_subj  = alpha_t * latents_subj  + sigma_t * noise\n",
    "    noisy_prior = alpha_t * latents_prior + sigma_t * noise\n",
    "\n",
    "    # --- Forward + Loss (mixed precision) ---\n",
    "    with autocast():\n",
    "        pred_subj  = pipe.unet(noisy_subj,  t, encoder_hidden_states=subj_embeds).sample\n",
    "        pred_prior = pipe.unet(noisy_prior, t, encoder_hidden_states=prior_embeds).sample\n",
    "\n",
    "        loss_subj  = F.mse_loss(pred_subj,  noise)\n",
    "        loss_prior = F.mse_loss(pred_prior, noise)\n",
    "        loss = loss_subj + lmbda * loss_prior\n",
    "\n",
    "    # --- Backprop & optimize ---\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(\n",
    "            f\"[{step:04d}] \"\n",
    "            f\"Loss: {loss.item():.4f} | \"\n",
    "            f\"Subj: {loss_subj.item():.4f} | \"\n",
    "            f\"Prior: {loss_prior.item():.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7415dff-0b0d-4f88-80b1-971240cb0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_skax_images(prompt, num_images=1, guidance_scale=7.5, num_inference_steps=100, height=512, width=512):\n",
    "    output = pipe(\n",
    "        prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_images_per_prompt=num_images,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "    )\n",
    "    return output.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6bf220bf-0e40-4d3a-832d-aed14b54a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 23.43it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"[skaz] drawing with a grass near the lake and people setting next to it drawn like [skaz]\"\n",
    "imgs = generate_skax_images(prompt,num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f19d5383-e162-4d7f-8b5d-62624af1e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, img in enumerate(imgs):\n",
    "    img.save(f\"skaz_{prompt.replace('[skaz]' ,'skaz').replace(' ','_')}_{idx}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3853f55-ce86-42b4-b566-cfbdef42e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fine-tuned dreambooth model.\n",
    "output_dir = \"dreambooth_skax_finetuned\"\n",
    "pipe.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c3fd4-0ced-41ec-970d-bfe0adfe5eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
